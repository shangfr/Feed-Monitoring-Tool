# -*- coding: utf-8 -*-
"""
Created on Mon Dec 25 11:01:26 2023

@author: shangfr
"""
import asyncio
import streamlit as st
from collections import defaultdict


st.set_page_config(page_title="ç½‘ç»œä¿¡æ¯ç›‘æ§APP", layout="wide", page_icon="ğŸ‘¨â€ğŸ’»")

st.write('''
<style>
button {
    height: auto;
    padding-top: 10px !important;
    padding-bottom: 10px !important;
}

[data-testid="column"] {
    width: calc(20% - 1rem) !important;
    flex: 1 1 calc(20% - 1rem) !important;
    min-width: calc(20% - 1rem) !important;
}
</style>''', unsafe_allow_html=True)


st.title('ğŸ‘¨â€ğŸ’»Feedè®¢é˜…ä¿¡æ¯å®æ—¶ç›‘æ§')

@st.cache_data
def agent(prompt = ''):

    return ""

import redis

pool = redis.ConnectionPool(host='localhost', port=6379, decode_responses=True)
r = redis.Redis(connection_pool=pool)


news_url = r.lrange("news_count", 0, -1)[::2]
news_cnt = r.lrange("news_count", 0, -1)[1::2]
news_cnt = [int(x) for x in news_cnt]
urls = list(set(news_url))
total = sum(news_cnt)


with st.sidebar:
   #st.info("ğŸ‘‰ç‚¹å‡»ğŸš—å¯åŠ¨ç›‘æ§ç¨‹åº")

    keywords = st.text_input('å…³é”®è¯', '(ç»¿è‰²|ä½ç¢³|å‡æ’|å‡ç¢³)',
                             help="ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ ¼å¼ï¼š(å…³é”®è¯1|å…³é”®è¯2)")
    col1, col2 = st.columns([2, 1])
    monitoring = col1.multiselect('ç›‘æ§å†…å®¹', ['æ ‡é¢˜', 'æ‘˜è¦'], ['æ ‡é¢˜', 'æ‘˜è¦'])
    interval = col2.number_input('è‡ªåŠ¨æ›´æ–°(s)', 10, 36000, 10, step=10)

    using_llm = st.toggle('LLM Monitoring', help="ä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œå†…å®¹ç›‘æ§")

    if using_llm:
        st.success(
            "ğŸ‘‡ğŸ¤– å¯åŠ¨LLM Monitoring [Agent](https://github.com/shangfr/MRKL-AgentBot)")
        prompt = st.text_area('ç›‘æ§éœ€æ±‚', 'è¯·ç›‘æ§äººå·¥æ™ºèƒ½ç›¸å…³çš„æ–°é—»èˆ†æƒ…', help="è¯­è¨€æè¿°ç›‘æ§éœ€æ±‚")
    else:
        prompt = ''


if 'results' not in st.session_state:
    st.session_state['results'] = defaultdict(list)
    st.session_state.run = False
    st.session_state.task_run = False


def run_state(flag):
    if flag == "start":
        st.session_state.run = True
        st.toast('Start!', icon='ğŸš—')
    elif flag == "stop":
        st.session_state.run = False
        st.toast('Stop!', icon='â›”ï¸')
    elif flag == "reset":
        st.session_state['results'] = defaultdict(list)
        st.session_state.run = False
        st.toast('Reset!', icon='ğŸ†‘')
    elif flag == "update":
        st.toast('Data Update!', icon='ğŸ”')


col1, col2, col3, col4 = st.columns([1, 1, 1, 1])

col1.button('ğŸš— å¼€å§‹', on_click=run_state, kwargs={
            'flag': "start"}, disabled=st.session_state.run, use_container_width=True, help="å¼€å§‹")
col2.button('â›”ï¸ æš‚åœ', on_click=run_state, kwargs={
            'flag': "stop"}, disabled=not st.session_state.run, use_container_width=True)
col3.button('ğŸ†‘ é‡ç½®', on_click=run_state, kwargs={
            'flag': "reset"}, disabled=st.session_state.run, use_container_width=True)
col4.button('ğŸ” æ›´æ–°', on_click=run_state, kwargs={
            'flag': "update"}, disabled=not st.session_state.run, use_container_width=True)


results = st.session_state['results']
#tab0, tab1, tab2 = st.tabs(["ğŸ“ˆ çŠ¶æ€", "ğŸ—ƒ æ•°æ®", "ğŸ¤– æ¨é€"])
###############################################################################

with st.expander("ğŸ“ˆ çŠ¶æ€", expanded=True):
    placeholder0 = st.empty()
    placeholder1 = st.empty()
 
placeholder2 = st.empty()

results = st.session_state['results']
feeds_num = len(results['uuid_set'])
if feeds_num == 0:
    placeholder0.progress(
        feeds_num % 100, text=f"ğŸ“ `{len(urls)}`ä¸ªæ•°æ®æºï¼ŒğŸ‘†ğŸš— å¯åŠ¨åï¼Œç‚¹å‡»æ›´æ–°ğŸ”æŒ‰é’®æŸ¥çœ‹æœ€æ–°æ•°æ®\n\n")
    placeholder1.info(f"**å…³é”®è¯**ï¼š{keywords}\n\n**ç›‘æ§åŒºåŸŸ**ï¼š" + "\n".join(monitoring) +
                      f"\n\n**è‡ªåŠ¨æ›´æ–°é—´éš”**ï¼š {str(interval)}ç§’")
    placeholder2.info(
        f"**RSS({len(urls)})**ï¼š\n\n> - " + "\n\n> - ".join(urls[-5:]))
else:

    source_num = len(results['source'])
    
    match_news = [item for item in results['news'] if item['match']]
    match_news_num = len(match_news)
    
    match_source = [item['source'] for item in match_news]
    match_source = list(set(match_source))
    match_source_num = len(match_source)
    

    ph0 = f"ğŸ“ å·²è·å–`{feeds_num}`æ¡ä¿¡æ¯ï¼ŒåŒ¹é…åˆ°`{len(match_news)}`æ¡ä¿¡æ¯"

    ph1 = f"â³ `æˆåŠŸè·å–{source_num}ä¸ªæ–°é—»æºï¼Œ{match_source_num}ä¸ªåŒ¹é…æºï¼š {'ã€'.join(match_source)}`"
    
    ph2 =  "\n\n".join([f"â­`{info['source']}` `{info['match']}`\n\n- [{info['title']}]({info['link']})"
                                for info in match_news[-20:]])

    placeholder0.progress(match_news_num % 100, text=ph0)
    placeholder1.success(ph1)
    placeholder2.markdown(ph2)

monitoring_dict = {'æ ‡é¢˜': 'title', 'æ‘˜è¦': 'summary'}


parm_dict = {
    "keywords": keywords,
    "monitoring": [monitoring_dict.get(m) for m in monitoring],
    "prompt": prompt,
    "results": st.session_state['results']
}

st_show = [placeholder0, placeholder1, placeholder2]
st_run = st.session_state["run"]

from utils import display_status,fetch_and_parse
async def fetch_query_results(urls, run=False, interval=5,st_show=[], **kwargs):
    print(f"å¯åŠ¨--{run}")
    while run:

        queue = asyncio.Queue()
        # start the consumer
        display_task = asyncio.create_task(display_status(st_show, queue))
        tasks = [fetch_and_parse(url, queue, **kwargs) for url in urls]

        await asyncio.gather(*tasks)
        await queue.join()
        display_task.cancel()
        # ç­‰å¾…ä»»åŠ¡å®é™…å®Œæˆï¼ˆå¦‚æœå®ƒå·²ç»å¼€å§‹æ‰§è¡Œï¼‰
        await display_task
        
        await asyncio.sleep(5)
        print(f"complete--{run}")


print(f"task_run---{st.session_state.task_run}")
print(f"st_run-----{st_run}")

if st.session_state.task_run and st_run:
    st.stop()

st.session_state.task_run = st_run
asyncio.run(fetch_query_results(urls, st_run, interval, st_show, **parm_dict))
st.stop()


    

